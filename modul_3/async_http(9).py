# Задача - Асинхронный HTTP-запрос. Продвинутая реализация.
# Напишите асинхронную функцию fetch_urls, которая принимает файл со списком урлов
# (каждый URL адрес возвращает JSON) и сохраняет результаты выполнения в другой
# файл (result.jsonl), где ключами являются URL, а значениями — распарсенный json,
# при условии что статус код — 200. Используйте библиотеку aiohttp для выполнения HTTP-запросов.
#
# Требования:
#
# Ограничьте количество одновременных запросов до 5
# Обработайте возможные исключения (например, таймауты, недоступные ресурсы) ошибок соединения
# Контекст:
#
# Урлов в файле может быть десятки тысяч
# Некоторые урлы могут весить до 300-500 мегабайт
# При внезапной остановке и/или перезапуске скрипта - допустимо скачивание урлов по новой.

# Пример файла results.json:
# {"url": "https://example1.com", "content": {"any key": "any value}
# {"url": "https://example2.com", "content": {"key": "value", ...}

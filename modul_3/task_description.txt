8) Напишите асинхронную функцию fetch_urls, которая принимает список URL-адресов и
возвращает словарь, где ключами являются URL, а значениями — статус-коды ответов.
Используйте библиотеку aiohttp для выполнения HTTP-запросов.

Требования:

Ограничьте количество одновременных запросов до 5 (используйте
примитивы синхронизации из asyncio библиотеки)
Обработайте возможные исключения (например, таймауты, недоступные ресурсы)
и присвойте соответствующие статус-коды (например, 0 для ошибок соединения).
Сохраните все результаты в файл
(решение вышеуказанной задачи в async_http(8))

9) Задача - Асинхронный HTTP-запрос. Продвинутая реализация.
Напишите асинхронную функцию fetch_urls, которая принимает файл со списком урлов
(каждый URL адрес возвращает JSON) и сохраняет результаты выполнения в другой
файл (result.jsonl), где ключами являются URL, а значениями — распарсенный json,
при условии что статус код — 200. Используйте библиотеку aiohttp для выполнения HTTP-запросов.

Требования:

Ограничьте количество одновременных запросов до 5
Обработайте возможные исключения (например, таймауты, недоступные ресурсы) ошибок соединения
Контекст:

Урлов в файле может быть десятки тысяч
Некоторые урлы могут весить до 300-500 мегабайт
При внезапной остановке и/или перезапуске скрипта - допустимо скачивание урлов по новой.
Пример файла results.json:
{"url": "https://example1.com", "content": {"any key": "any value}
{"url": "https://example2.com", "content": {"key": "value", ...}
(решение вышеуказанной задачи в async_http(9))
